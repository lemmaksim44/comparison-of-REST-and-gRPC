# Comparison of REST and gRPC

REST: https://github.com/lemmaksim44/rest-fastapi-swagger

gRPC: https://github.com/lemmaksim44/rpc-grpc-protobuf

## Конфигурация тестовой среды

- ОС: 64-разрядная операционная система (Windows)
- Процессор: Intel(R) Core(TM) i7-5500U (2-ядерный / 4 потока, x64, 2.40 GHz)
- Оперативная память: 8 GB
- Сеть: локальная docker-сеть
- Docker: запуск всех сервисов в отдельных контейнерах

### Архитектура тестового стенда

- SQLite - встроенная база данных для хранения данных
- FastAPI REST сервис - реализация API через HTTP/JSON
- gRPC сервис - реализация API через protobuf RPC
- Locust - генератор нагрузки

### Фрагменты тестового кода

```python
from locust import HttpUser, task, between
import random
import string

class User(HttpUser):
    wait_time = between(0.5, 1)

    def random_keyword(self):
        return "term_" + ''.join(random.choices(string.ascii_lowercase, k=8))

    @task
    def get_all_terms(self):
        self.client.get("/terms")

    @task
    def get_one_term(self):
        self.client.get("/terms/Honeypot")

    @task
    def create_term(self):
        kw = self.random_keyword()
        data = {
            "keyword": kw,
            "description": "Created by Locust"
        }
        self.client.post("/terms", json=data)

    @task
    def update_term(self):
        data = {
            "description": "Updated by Locust"
        }
        self.client.put("/terms/Honeypot", json=data)
```

### Light-load тест
| Параметр     | Значение       |
| ------------ | -------------- |
| Пользователи | **25**         |
| Spawn rate   | **4**          |
| Длительность | **70 секунд**  |

#### Гипотезы:
- все сервисы стартуют без ошибок;  
- средняя задержка небольшая (2–12 ms);  
- различия между REST и gRPC будут, но не критичны;  
- нагрузка умеренная (RPS 120–210 запросов/с).  

#### Результаты

| Метрика                       | REST           | gRPC           |
| ----------------------------- | -------------- | -------------- |
| **Requests per second (RPS)** | ~38             | ~39             |
| **Average latency**           | **8–9 ms**     | **4–6 ms**     |
| **Median (50%)**              | 7–9 ms         | 4–5 ms         |
| **p95**                       | 14–16 ms       | 7–9 ms         |
| **p99**                       | 20–21 ms       | 9–14 ms        |
| **Минимум**                   | 3 ms           | 1–3 ms         |
| **Максимум**                  | 50–100 ms      | 25–45 ms       |
| **Ошибки**                    | 0              | 0              |

#### Выводы
Оба сервиса корректно справились с лёгкой нагрузкой: ошибок не зафиксировано, задержки оставались стабильными. REST и gRPC показали схожий RPS, однако gRPC оказался быстрее: медианная задержка на 35–50% ниже, а значения p95 и p99 почти вдвое меньше. Минимальная задержка gRPC составила 1–3 мс, в то время как у REST наблюдались единичные всплески до 100 мс. Система проявила стабильность и готова к тестам с более высокой нагрузкой.  

### Рабочая нагрузка (нормальный режим)
| Параметр     | Значение    |
| ------------ | ----------- |
| Пользователи | **220**     |
| Spawn rate   | **15**      |
| Длительность | **5 минут** |

#### Гипотезы:
- REST начнёт демонстрировать рост p95/p99;  
- gRPC сохранит стабильную производительность;  
- RPS ожидается на уровне 320–480 запросов/с;  
- ошибок не ожидается, но возможны единичные таймауты при REST.  

#### Результаты:
| Метрика                       | REST         | gRPC        |
| ----------------------------- | ------------ | ----------- |
| **Requests per second (RPS)** | ~150–165     | ~150–165    |
| **Average latency**           | **20–27 ms** | **10–14 ms**|
| **Median (50%)**              | 17–22 ms     | 8–10 ms     |
| **p95**                       | 38–48 ms     | 16–22 ms    |
| **p99**                       | 60–85 ms     | 24–32 ms    |
| **Минимум**                   | 7–9 ms       | 2–4 ms      |
| **Максимум**                  | 190–260 ms   | 75–115 ms   |
| **Ошибки**                    | 0            | 0           |

#### Выводы
Под рабочей нагрузкой оба сервиса продолжают работать стабильно, ошибок не зафиксировано. gRPC сохраняет низкие задержки и ровное распределение латентности. REST показывает больший разброс задержек при увеличении нагрузки, что характерно для работы через HTTP/JSON. Отличие между REST и gRPC становится заметнее, особенно по значениям p95 и p99, где gRPC демонстрирует почти вдвое меньшие пики задержки.

### Стресс-тест
| Параметр     | Значение    |
| ------------ |------------ |
| Пользователи | **1000**   |
| Spawn rate   | **100**    |
| Длительность | **5 минуты** |

#### Гипотезы
- REST начнёт деградировать примерно после 300–400 пользователей;  
- p99 REST может достигать 220–320 ms;  
- вероятны ошибки 5xx и таймауты;  
- gRPC справится лучше благодаря лёгкой protobuf-сериализации.  

#### Результаты
| Метрика                       | REST         | gRPC         |
| ----------------------------- | ------------ | ------------ |
| **Requests per second (RPS)** | ~320–340     | ~320–340     |
| **Average latency**           | **60–80 ms** | **25–35 ms** |
| **Median (50%)**              | 55–70 ms     | 20–28 ms     |
| **p95**                       | 115–145 ms   | 50–65 ms     |
| **p99**                       | 190–240 ms   | 75–100 ms    |
| **Минимум**                   | 14–18 ms     | 5–7 ms       |
| **Максимум**                  | 470–680 ms   | 170–280 ms   |
| **Ошибки**                    | 0            | 0            |

#### Выводы
Оба сервиса выдержали резкий рост нагрузки, ошибок не зафиксировано, но наблюдаются различия:  
- REST начинает деградировать уже при 150 одновременных пользователей, с резким ростом задержек;  
- gRPC остаётся стабильным и почти в 2–3 раза быстрее по средней и медианной задержке;  
- пики максимальной latency у REST достигают почти 680 ms, тогда как у gRPC рост задержки плавный и контролируемый;  
- система не вышла из строя, но REST близок к пределу возможностей при текущей нагрузке.

### Тест стабильности
| Параметр     | Значение                 |
| ------------ |--------------------------|
| Пользователи | **250**                  |
| Spawn rate   | **10**                   |
| Длительность | **31 минута**  |

#### Гипотезы:
- REST latency будет постепенно расти;  
- gRPC останется стабильным за счёт меньших накладных расходов;  

#### Результаты
| Метрика                       | REST         | gRPC         |
| ----------------------------- | ------------ | ------------ |
| **Requests per second (RPS)** | ~170–180     | ~170–180     |
| **Average latency**           | **24–38 ms** | **12–16 ms** |
| **Median (50%)**              | 22–30 ms     | 10–13 ms     |
| **p95**                       | 58–75 ms     | 22–32 ms     |
| **p99**                       | 100–135 ms   | 37–52 ms     |
| **Минимум**                   | 8–11 ms      | 3–5 ms       |
| **Максимум**                  | 260–360 ms   | 95–145 ms    |
| **Ошибки**                    | 0            | 0            |

#### Выводы
- gRPC сохраняет предсказуемую производительность: задержка почти вдвое ниже, чем у REST, даже после длительного времени работы.  
- REST показывает постепенный рост latency, особенно в p95/p99, что указывает на накопление очередей или увеличение накладных расходов при обработке JSON.  
- Пики максимальной latency у REST достигают 360+ мс, тогда как у gRPC рост задержки плавный и контролируемый.  
- Системные ресурсы оказались достаточными для длительной работы, признаков перегрузки не наблюдалось.

## Заключение

В ходе тестов были проверены два варианта сервиса словаря: REST (FastAPI) и gRPC (Python + protobuf) по четырём сценариям: лёгкая нагрузка, рабочий режим, стресс и стабильность. Во всех случаях сервисы работали корректно, ошибок не было, а RPS оставался стабильным.

gRPC продемонстрировал более низкую латентность (на 40–60% меньше) и более предсказуемое распределение задержек (p95/p99). Даже при высокой нагрузке gRPC сохранял стабильность, тогда как REST быстрее достигал точки деградации и показывал всплески задержек. Это делает gRPC предпочтительным для высоконагруженных внутренних микросервисов, а REST — удобным для внешних HTTP-клиентов и интеграций.

Ссылка на тесты: https://drive.google.com/drive/folders/1jrHNOh5slftRoXA87SvnCU-Sz6cFvyM2?usp=sharing

---

## Возможные улучшения эксперимента

- Провести тесты с большим объёмом данных.  
- Отслеживать системные метрики сервисов (CPU, RAM, диск) для выявления потенциальных узких мест.  

---

## Ограничения тестирования

- Тесты проводились в локальной Docker-среде, где сетевые задержки ниже реальных условий.  
- Объём данных был сравнительно небольшой, что снижает нагрузку на базу данных.  
- Один Docker-хост исключает влияние внешних сетевых факторов.  
- Нагрузка ограничена возможностями одного Locust-инстанса (без кластерного режима).  

---

## Рекомендации по оптимизации

**REST сервис:**  
- увеличить количество worker-процессов Uvicorn/Gunicorn;  
- использовать более быстрые JSON-сериализаторы (orjson, ujson);  
- добавить кэширование популярных запросов;  

**gRPC сервис:**  
- включить сжатие сообщений (gzip);  
- настроить connection pooling;  
